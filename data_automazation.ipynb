{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apresentação: Plano de Desenvolvimento e Sustentação para Simplificação e Automatização de Processos de Dados - PTBR\n",
    "\n",
    "## Introdução\n",
    "\n",
    "**Contexto:**\n",
    "A empresa enfrenta desafios significativos com seus processos manuais, que são demorados e propensos a erros. Atualmente, a extração e manipulação de planilhas são realizadas de forma manual, e os dados resultantes precisam ser integrados em um sistema de Business Intelligence (BI).\n",
    "\n",
    "## Proposta de Solução\n",
    "\n",
    "### Linguagem de Programação e Frameworks:\n",
    "\n",
    "**Escolha de Python:**\n",
    "- **Justificativa:**\n",
    "  - Python foi escolhido devido à sua robustez para manipulação de dados e integração de sistemas.\n",
    "  - Sua vasta comunidade e bibliotecas especializadas o tornam ideal para tarefas de ciência de dados e automação.\n",
    "\n",
    "- **Detalhes de Implementação:**\n",
    "  - Scripts em Python serão desenvolvidos para realizar a manipulação e transformação dos dados.\n",
    "  - O uso de ambientes virtuais garantirá a consistência e isolamento das dependências.\n",
    "\n",
    "**Utilização do Apache Airflow:**\n",
    "- **Justificativa:**\n",
    "  - O Apache Airflow oferece uma estrutura robusta para orquestração de tarefas, permitindo a criação de DAGs para automatizar fluxos de trabalho complexos.\n",
    "\n",
    "- **Detalhes de Implementação:**\n",
    "  - DAGs serão configurados para representar os fluxos de trabalho, definindo a sequência de tarefas e suas dependências.\n",
    "  - A escalabilidade será garantida pela arquitetura distribuída do Apache Airflow.\n",
    "\n",
    "### Conexão com Fontes de Dados:\n",
    "\n",
    "**Utilização da API disponível no portal da internet:**\n",
    "- **Detalhes de Implementação:**\n",
    "  - Autenticação segura será realizada via token para garantir a integridade dos dados extraídos.\n",
    "  - Rotinas de retry e controle de falhas serão implementadas para assegurar a robustez da extração, lidando proativamente com possíveis interrupções.\n",
    "\n",
    "### Serviço Cloud:\n",
    "\n",
    "**Adoção da infraestrutura do AWS:**\n",
    "- **Detalhes de Implementação:**\n",
    "  - Contas e roles da AWS serão configuradas para garantir permissões mínimas necessárias.\n",
    "  - O Amazon S3 será utilizado para armazenamento temporário e persistência, aproveitando sua durabilidade e escalabilidade.\n",
    "\n",
    "**AWS Lambda para execução de funções sem servidor:**\n",
    "- **Detalhes de Implementação:**\n",
    "  - Funções Lambda específicas serão desenvolvidas para tarefas granulares, e gatilhos serão configurados para acionar automaticamente essas funções em resposta a eventos específicos.\n",
    "  - Isso garantirá a escalabilidade automática com base na demanda.\n",
    "\n",
    "### Localização da Ferramenta:\n",
    "\n",
    "**Implantação na AWS:**\n",
    "- **Detalhes de Implementação:**\n",
    "  - Serviços gerenciados da AWS, como ECS ou EKS, serão utilizados para hospedar a aplicação, garantindo acesso remoto e alta disponibilidade.\n",
    "  - O AWS Step Functions será empregado para gerenciar e coordenar eficientemente a execução dos diferentes componentes.\n",
    "\n",
    "## Fluxo da Solução\n",
    "\n",
    "### Extração de Dados:\n",
    "\n",
    "**Configuração da API:**\n",
    "- **Detalhes de Implementação:**\n",
    "  - A API será configurada para extração automática, utilizando autenticação segura para acessar dados relevantes.\n",
    "  - O AWS Lambda será agendado para executar a extração diariamente, garantindo atualizações frequentes.\n",
    "\n",
    "**Armazenamento no Amazon S3:**\n",
    "- **Detalhes de Implementação:**\n",
    "  - Os dados extraídos serão temporariamente armazenados no Amazon S3, proporcionando fácil acesso e escalabilidade.\n",
    "  - A estratégia de armazenamento será otimizada para garantir eficiência e minimizar custos.\n",
    "\n",
    "### Manipulação e Transformação de Dados:\n",
    "\n",
    "**Desenvolvimento de Scripts em Python:**\n",
    "- **Detalhes de Implementação:**\n",
    "  - Scripts modulares em Python serão desenvolvidos, utilizando bibliotecas como Pandas para manipulação e transformação eficiente.\n",
    "  - Controle de versão será realizado utilizando Git para rastreabilidade e colaboração eficiente.\n",
    "\n",
    "**Validações Automáticas:**\n",
    "- **Detalhes de Implementação:**\n",
    "  - Mecanismos de validação automáticos serão implementados para garantir a qualidade dos dados.\n",
    "  - Essas validações incluirão verificações de consistência, integridade e conformidade com padrões pré-definidos.\n",
    "\n",
    "### Alimentação no Sistema de BI:\n",
    "\n",
    "**Exportação dos Dados Transformados:**\n",
    "- **Detalhes de Implementação:**\n",
    "  - Os dados transformados serão exportados para um formato compatível com o sistema de BI, garantindo a integração eficiente.\n",
    "  - O pipeline será integrado ao AWS Data Pipeline para orquestrar a carga no BI.\n",
    "\n",
    "**Atualização Programada do BI:**\n",
    "- **Detalhes de Implementação:**\n",
    "  - A atualização do BI será programada, utilizando recursos internos do sistema de BI ou, quando aplicável, serviços específicos da AWS, como o Amazon Redshift.\n",
    "  - Essa estratégia assegurará que os dados estejam sempre sincronizados e prontos para análise.\n",
    "\n",
    "## Sustentabilidade a Longo Prazo\n",
    "\n",
    "### Monitoramento e Logs:\n",
    "\n",
    "**Implementação de Logs Detalhados:**\n",
    "- **Detalhes de Implementação:**\n",
    "  - Logs detalhados serão implementados usando AWS CloudWatch para monitoramento em tempo real.\n",
    "  - Configuração de alertas permitirá a notificação proativa sobre falhas ou degradação de desempenho.\n",
    "\n",
    "### Documentação:\n",
    "\n",
    "**Criação de Documentação Abrangente:**\n",
    "- **Detalhes de Implementação:**\n",
    "  - Documentação completa será criada, abrangendo instruções de implantação, configuração e manutenção.\n",
    "  - Ferramentas como Sphinx ou MkDocs serão utilizadas para criar documentação dinâmica, garantindo atualizações fáceis e compreensíveis.\n",
    "\n",
    "### Automatização de Testes:\n",
    "\n",
    "**Desenvolvimento de Testes Automatizados:**\n",
    "- **Detalhes de Implementação:**\n",
    "  - Testes automatizados serão desenvolvidos utilizando frameworks como Pytest.\n",
    "  - A integração contínua será realizada através do AWS CodePipeline, garantindo automação e estabilidade contínua do pipeline.\n",
    "\n",
    "## Conclusão\n",
    "\n",
    "- **Recapitulação dos Benefícios:**\n",
    "  - A solução proposta proporcionará eficiência operacional, confiabilidade nos processos e escalabilidade para atender às demandas crescentes.\n",
    "\n",
    "- **Ênfase na Sustentabilidade:**\n",
    "  - A abordagem sustentável e replicável é destacada, evidenciando a escolha de tecnologias e práticas que minimizam a dívida tecnológica.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Presentation: Development and Sustainability Plan for Simplification and Automation of Data Processes - ENG\n",
    "\n",
    "## Introduction\n",
    "\n",
    "**Context:**\n",
    "The company faces significant challenges with its manual processes, which are time-consuming and error-prone. Currently, the extraction and manipulation of spreadsheets are done manually, and the resulting data needs to be integrated into a Business Intelligence (BI) system.\n",
    "\n",
    "## Solution Proposal\n",
    "\n",
    "### Programming Language and Frameworks:\n",
    "\n",
    "**Choice of Python:**\n",
    "- **Justification:**\n",
    "  - Python was chosen for its robustness in data manipulation and system integration.\n",
    "  - Its extensive community and specialized libraries make it ideal for data science tasks and automation.\n",
    "\n",
    "- **Implementation Details:**\n",
    "  - Python scripts will be developed to perform data manipulation and transformation.\n",
    "  - The use of virtual environments will ensure consistency and isolation of dependencies.\n",
    "\n",
    "**Use of Apache Airflow:**\n",
    "- **Justification:**\n",
    "  - Apache Airflow provides a robust framework for task orchestration, allowing the creation of Directed Acyclic Graphs (DAGs) to automate complex workflows.\n",
    "\n",
    "- **Implementation Details:**\n",
    "  - DAGs will be configured to represent workflows, defining the sequence of tasks and their dependencies.\n",
    "  - Scalability will be ensured by the distributed architecture of Apache Airflow.\n",
    "\n",
    "### Connection to Data Sources:\n",
    "\n",
    "**Use of the API available on the internet portal:**\n",
    "- **Implementation Details:**\n",
    "  - Secure authentication will be performed via token to ensure the integrity of extracted data.\n",
    "  - Retry routines and fault control will be implemented to ensure the robustness of extraction, proactively handling possible interruptions.\n",
    "\n",
    "### Cloud Service:\n",
    "\n",
    "**Adoption of AWS Infrastructure:**\n",
    "- **Implementation Details:**\n",
    "  - AWS accounts and roles will be configured to ensure minimal necessary permissions.\n",
    "  - Amazon S3 will be used for temporary storage and persistence, leveraging its durability and scalability.\n",
    "\n",
    "**AWS Lambda for serverless function execution:**\n",
    "- **Implementation Details:**\n",
    "  - Specific Lambda functions will be developed for granular tasks, and triggers will be configured to automatically invoke these functions in response to specific events.\n",
    "  - This will ensure automatic scalability based on demand.\n",
    "\n",
    "### Tool Location:\n",
    "\n",
    "**Deployment in AWS:**\n",
    "- **Implementation Details:**\n",
    "  - Managed AWS services, such as ECS or EKS, will be used to host the application, ensuring remote access and high availability.\n",
    "  - AWS Step Functions will be employed to manage and coordinate the efficient execution of different components.\n",
    "\n",
    "## Solution Flow\n",
    "\n",
    "### Data Extraction:\n",
    "\n",
    "**API Configuration:**\n",
    "- **Implementation Details:**\n",
    "  - The API will be configured for automatic extraction, using secure authentication to access relevant data.\n",
    "  - AWS Lambda will be scheduled to execute extraction daily, ensuring frequent updates.\n",
    "\n",
    "**Storage in Amazon S3:**\n",
    "- **Implementation Details:**\n",
    "  - Extracted data will be temporarily stored in Amazon S3, providing easy access and scalability.\n",
    "  - The storage strategy will be optimized for efficiency and cost minimization.\n",
    "\n",
    "### Data Manipulation and Transformation:\n",
    "\n",
    "**Development of Python Scripts:**\n",
    "- **Implementation Details:**\n",
    "  - Modular Python scripts will be developed, using libraries like Pandas for efficient manipulation and transformation.\n",
    "  - Version control will be performed using Git for traceability and efficient collaboration.\n",
    "\n",
    "**Automatic Validations:**\n",
    "- **Implementation Details:**\n",
    "  - Automatic validation mechanisms will be implemented to ensure data quality.\n",
    "  - These validations will include checks for consistency, integrity, and compliance with predefined standards.\n",
    "\n",
    "### Feeding into the BI System:\n",
    "\n",
    "**Export of Transformed Data:**\n",
    "- **Implementation Details:**\n",
    "  - Transformed data will be exported to a format compatible with the BI system, ensuring efficient integration.\n",
    "  - The pipeline will be integrated with AWS Data Pipeline to orchestrate loading into BI.\n",
    "\n",
    "**Scheduled BI Update:**\n",
    "- **Implementation Details:**\n",
    "  - BI updates will be scheduled using internal BI system resources or, when applicable, specific AWS services such as Amazon Redshift.\n",
    "  - This strategy will ensure that data is always synchronized and ready for analysis.\n",
    "\n",
    "## Long-term Sustainability\n",
    "\n",
    "### Monitoring and Logs:\n",
    "\n",
    "**Implementation of Detailed Logs:**\n",
    "- **Implementation Details:**\n",
    "  - Detailed logs will be implemented using AWS CloudWatch for real-time monitoring.\n",
    "  - Alert configurations will proactively notify about failures or performance degradation.\n",
    "\n",
    "### Documentation:\n",
    "\n",
    "**Creation of Comprehensive Documentation:**\n",
    "- **Implementation Details:**\n",
    "  - Comprehensive documentation will be created, covering deployment, configuration, and maintenance instructions.\n",
    "  - Tools like Sphinx or MkDocs will be used to create dynamic documentation, ensuring easy and understandable updates.\n",
    "\n",
    "### Test Automation:\n",
    "\n",
    "**Development of Automated Tests:**\n",
    "- **Implementation Details:**\n",
    "  - Automated tests will be developed using frameworks like Pytest.\n",
    "  - Continuous integration will be achieved through AWS CodePipeline, ensuring automation and continuous stability of the pipeline.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "- **Recap of Benefits:**\n",
    "  - The proposed solution will provide operational efficiency, process reliability, and scalability to meet growing demands.\n",
    "\n",
    "- **Emphasis on Sustainability:**\n",
    "  - The sustainable and replicable approach is highlighted, emphasizing the choice of technologies and practices that minimize technological debt.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
